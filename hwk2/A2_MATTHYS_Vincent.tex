\documentclass{article}
\input{packages}
\input{macros}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Header
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewcommand{\assignmenttitle}{Assignment 2 :Image classification}
\renewcommand{\studentname}{Vincent Matthys}
\renewcommand{\email}{vincent.matthys@ens-paris-saclay.fr}

% renew (sub)section to get alpanumeric characters
\renewcommand{\thesection}{\Alph{section}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Syntax for using figure macros:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \singlefig{filename}{scalefactor}{caption}{label}
% \doublefig{\subfig{filename}{scalefactor}{subcaption}{sublabel}}
%           {\subfig{filename}{scalefactor}{subcaption}{sublabel}}
%           {global caption}{label}
% \triplefig{\subfig{filename}{scalefactor}{subcaption}{sublabel}}
%           {\subfig{filename}{scalefactor}{subcaption}{sublabel}}
%           {\subfig{filename}{scalefactor}{subcaption}{sublabel}}
%           {global caption}{label}
%
% Tips:
% - with scalefactor=1, a single figure will take the whole page width; a double figure, half page width; and a triple figure, a third of the page width
% - image files should be placed in the image folder
% - no need to put image extension to include the image
% - for vector graphics (plots), pdf figures are suggested
% - for images, jpg/png are suggested
% - labels can be left empty {}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beginning of assignment
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\maketitle

\part{Training and testing an Image Classifier}

\section{Data preparation and feature extraction}


\question{QA1: Why is the spatial tiling used in the histogram image representation?}

The spatial tiling is a way to keep spatial information about relative positions of features, which should help to refine the correspondances, by having a representation of words in a space of dimesnion \( 128 \times nbr_{tiles}\).

\section{Train a classifier for images containing aeroplanes}

\question{QB1: Show the ranked training images in your report.}

\begin{figure}[ht!]
	\centering
	\includegraphics[width = 1.0\textwidth]{1B1_C_10}
	\caption{Ranking of a subset of 36 training images with \( C = 10\)}
	\label{fig_1B1}
\end{figure}
A subset of \(36\) training images is ranked in figure~\ref{fig_1B1}, with the score of each one, as computed by the learned SVM classifier for a value of the regularization parameter C of \(10\). It should be noticed that the indicated score is only qualitative, and has to be compared with the score of another image, \textit{i.d} images should be ranked in function of their respective score.

\clearpage
\question{QB2: In your report, show relevant patches for the three most relevant visual words (in three separate figures) for the top ranked training image. Are the most relevant visual words on the airplane or also appear on background?}

\begin{figure}[ht!]
	\centering
	\includegraphics[width = 1.0\textwidth]{1B2_vw_1}
	\caption{Relevant patches for the first most relevant visual word and for the first ranking image of the same subset as in figure~\ref{fig_1B1}, and their positions in the image}
	\label{fig_1B2_vw_1}
\end{figure}

\begin{figure}[ht!]
	\centering
	\includegraphics[width = 1.0\textwidth]{1B2_vw_2}
	\caption{Relevant patches for the second most relevant visual word and for the first ranking image of the same subset as in figure~\ref{fig_1B1}, and their positions in the image}
	\label{fig_1B2_vw_2}
\end{figure}

\begin{figure}[ht!]
	\centering
	\includegraphics[width = 1.0\textwidth]{1B2_vw_3}
	\caption{Relevant patches for the third most relevant visual word and for the first ranking image of the same subset as in figure~\ref{fig_1B1}, and their positions in the image}
	\label{fig_1B2_vw_3}
\end{figure}

In figures~\ref{fig_1B2_vw_1}~\ref{fig_1B2_vw_2}~\ref{fig_1B2_vw_3}, the patches associated to the first three most relevant visual words are shown, with their positions on the first ranked image of the subset as shown in figure~\ref{fig_1B1}. It is important to notice, as shown in the three figures, in patches and in their locations, that the three most relevant visual words are essentially located in the background, in the forest in figure~\ref{fig_1B2_vw_1}, in the tarmac in figure~\ref{fig_1B2_vw_2}, in the sky in figure~\ref{fig_1B2_vw_3}, and not in the airplane.

\clearpage

\section{Classify the test images and assess the performance}

\question{QC1: Why is the bias term not needed for the image ranking?}

In the image ranking, the bias is a constant term, wich doesn't change the ranks. It's then not needed. The important part is the \( w^{\intercal} \cdot h\).

\section{Learn a classifier for the other classes and assess its performance}

\question{QD1: In your report, show the top ranked images, precision-recall curves and APs for the test data of all the three classes (aeroplanes, motorbikes, and persons). Does the AP performance for the different classes match your expectations based on the variation of the class images?}

In figures~\ref{fig_1D1_aeroplanes}~\ref{fig_1D1_motorbikes}~\ref{fig_1D1_persons} are shown the SVM classifier learnt respectively on classes aeroplanes, motorbikes and persons. It's interesting to notice that the AP value is quite similar between the aeroplanes (\(54.95~\%\)) and the motorbikes (\(48.66~\%\)) class, when the AP value for the persons class is much higher (\(70.64~\%\)). This fact can be explain by the inner-class variation, which is reasonably smaller for the persons because of their face, which is approximately constant in shape for every human. On the other hand, the aeroplanes and motorbikes can vary, for the first in term of paintings, and for the second in term of shape and paintings in between wheels. The paintings (= inner-class variations) change may be interpreted as change in gradients directions and values for SIFT descriptors, and therefore for change in visual words.

\begin{figure}[ht!]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\centering
		\includegraphics[width = 1.0\textwidth]{1D1_aeroplanes_C_10}
		\subcaption{Ranking of a subset of 36 testing images with \( C = 10\) : \(24\) over \(36\) images are correctly retrieved.}
		\label{fig_1D1_aeroplanes_a}
	\end{subfigure}
	\begin{subfigure}[b]{0.8\textwidth}
		\centering
		\includegraphics[width = 1.0\textwidth]{1D1_aeroplanes_AP_test_C_10}
		\subcaption{Precision-recall curve for the test data. \(AP = 54.95~\%\)}
		\label{fig_1D1_aeroplanes_b}
	\end{subfigure}
	\caption{SVM Classifier learnt for aeroplanes class}
	\label{fig_1D1_aeroplanes}
\end{figure}

\begin{figure}[ht!]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\centering
		\includegraphics[width = 1.0\textwidth]{1D1_motorbikes_C_10}
		\subcaption{Ranking of a subset of 36 testing images with \( C = 10\) : \(24\) over \(36\) images are correctly retrieved.}
		\label{fig_1D1_motorbikes_a}
	\end{subfigure}
	\begin{subfigure}[b]{0.8\textwidth}
		\centering
		\includegraphics[width = 1.0\textwidth]{1D1_motorbikes_AP_test_C_10}
		\subcaption{Precision-recall curve for the test data. \(AP = 48.66~\%\)}
		\label{fig_1D1_motorbikes_b}
	\end{subfigure}
	\caption{SVM Classifier learnt for motorbikes class}
	\label{fig_1D1_motorbikes}
\end{figure}

\begin{figure}[ht!]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\centering
		\includegraphics[width = 1.0\textwidth]{1D1_persons_C_10}
		\subcaption{Ranking of a subset of 36 testing images with \( C = 10\) : \(33\) over \(36\) images are correctly retrieved.}
		\label{fig_1D1_persons_a}
	\end{subfigure}
	\begin{subfigure}[b]{0.8\textwidth}
		\centering
		\includegraphics[width = 1.0\textwidth]{1D1_persons_AP_test_C_10}
		\subcaption{Precision-recall curve for the test data. \(AP = 70.64~\%\)}
		\label{fig_1D1_persons_b}
	\end{subfigure}
	\caption{SVM Classifier learnt for persons class}
	\label{fig_1D1_persons}
\end{figure}

\clearpage
\question{QD2: For the motorbike class, give the rank of the first false positive image. What point on the precision-recall curve corresponds to this first false positive image? Give in your report the value of precision and recall for that point on the precision-recall curve.}

For the motorbike class, the first false positive image, visible in figure~\ref{fig_1D1_motorbikes_a}, is the top scoring one (\textit{006687.jpg}), which corresponds to the point \( (Recall(2), Precision(2)) = (0,0)\) on the precision-recall curve, \textit{i.e.} the first point of the precision-recall curve, after the conventional  \( (Recall(1), Precision(1)) = (0,1)\).

\section{Vary the image representation}

\question{QE1: Include in your report precision recall-curves and APs, and compare the test performance to the spatially tiled representation in stage D. How is the performance changing? Why?}

\begin{figure}[ht!]
	\centering
	\includegraphics[width = 1.0\textwidth]{1E1_aeroplanes_AP_test_C_10}
	\caption{SVM Classifier learnt for aeroplanes class : Precision-recall curve for the test data. \(AP = 51.82~\%\)}
	\label{fig_1E1_aeroplanes}
\end{figure}

\begin{figure}[ht!]
	\centering
	\includegraphics[width = 1.0\textwidth]{1E1_motorbikes_AP_test_C_10}
	\caption{SVM Classifier learnt for motorbikes class : Precision-recall curve for the test data. \(AP = 41.54~\%\)}
	\label{fig_1E1_motorbikes}
\end{figure}

\begin{figure}[ht!]
	\centering
	\includegraphics[width = 1.0\textwidth]{1E1_persons_AP_test_C_10}
	\caption{SVM Classifier learnt for persons class : Precision-recall curve for the test data. \(AP = 69.61~\%\)}
	\label{fig_1E1_persons}
\end{figure}

For the three classes, the AP value decreases respectively by \(3~\%\),  \(7~\%\) and \(1~\%\) for aeroplanes, motorbikes and persons. These variations are class dependants, meaning that the spatial information brought by the spatial tiling is more relevant for the motorbikes, then for aeroplanes and finaly for persons. This might be correlated with the inner-class variation, as the decrease is inverse-proportional to the initial AP-value.

\clearpage

\question{QE2: Modify exercise1.m to use L1 normalization and no normalization and measure the performance change.}


\clearpage

The two classification boundaries are shown in Figure~\ref{fig:overfit}. As it can be observed, model A, represented in green, is producing a very irregular classification boundary which gives a training error of zero, while model B, represented in black, is producing a smoother classification boundary which mis-classifies a few examples of the training data.

However, although the training error is higher for model B than for model A, we expect model B to perform better on the test data, as its smoother classification boundary is more robust to the noise in the training data, while model A is overfitting to the noise in this particular training data.

It is therefore concluded that model B is superior, as it will offer better generalization properties.

\singlefig{overfitting_vectorial}{0.45}{Two different models for fitting the data. The classification boundaries for models A and B are shown in green and black respectively.}{fig:overfit}

\question{QIA.3: Show the detected features in the image for three different values of the peakThreshold option.}

The detected features with three different values of $peakThreshold$ are shown in Figure~\ref{fig:peakThreshold}. % if we want to refer to one particular subplot, we can use its sublabel instead: e.g. \ref{fig:th_0.0001}

\triplefig{\subfig{features_th1}{1}{$peakThreshold = 0.0001$}{fig:th_0.0001}} % sublabels used here
{\subfig{features_th2}{1}{$peakThreshold = 0.001$}{fig:th_0.001}}
{\subfig{features_th3}{1}{$peakThreshold = 0.01$}{fig:th_0.01}}
{Feature detectors with three different values of $peakThreshold$}{fig:peakThreshold}

\end{document}
